
ğŸ“ Real-Time File Processing System
A modular, fault-tolerant, and extensible file processing pipeline that supports both single-file execution and continuous directory watching. It includes a live Flask dashboard for real-time monitoring of file states.

ğŸš€ Key Features
âœ… Dual Execution Modes: Process a single file or continuously monitor a folder

ğŸ“Š Live Flask Dashboard: Track files being processed in real-time

ğŸ”§ CLI Configurable: Run via CLI flags or Makefile

ğŸ³ Docker Compatible: Containerized deployment supported

ğŸ› ï¸ Makefile & Shell Script Support: Easy automation with Makefile and run.sh

ğŸ“‚ Auto-organized Folders: Handles unprocessed/, underprocess/, and processed/ directories




ğŸ“¦ Project Structure
bash
Copy code
dataflow-framework/
â””â”€â”€ abstraction-level-8/
    â”œâ”€â”€ file_processor.py     # Core file processing logic
    â”œâ”€â”€ watcher.py            # Monitors folder for new files
    â”œâ”€â”€ dashboard.py          # Flask dashboard for real-time tracking
    â”œâ”€â”€ main.py               # CLI entry point
    â”œâ”€â”€ Makefile              # Automation commands
    â”œâ”€â”€ run.sh                # Shell script alternative to Makefile
    â”œâ”€â”€ requirements.txt      # Python dependencies
    â””â”€â”€ watch_dir/
        â”œâ”€â”€ unprocessed/      # Place files here to be processed
        â”œâ”€â”€ underprocess/     # Files currently being handled
        â””â”€â”€ processed/        # Successfully processed files
ğŸ› ï¸ Setup Instructions
ğŸ”§ Local Setup
Clone the repository

bash
Copy code
git clone https://github.com/sejal1234desai/bootcamp
cd dataflow-framework/abstraction-level-8
Create and activate a virtual environment

bash
Copy code
uv venv venv
source venv/bin/activate  # For Windows: venv\Scripts\activate
pip install -r requirements.txt
ğŸ§ª Execution Modes
ğŸ”¹ Single File Mode
Process a single file and exit.

bash
Copy code
make input file=watch_dir/unprocessed/test.txt
ğŸ”¹ Watch Mode
Continuously watch the unprocessed/ folder for new files and process them.

bash
Copy code
make watch
ğŸŒ Dashboard Access
Once the application is running, open your browser and navigate to:

http://localhost:5000

Dashboard displays:

ğŸ“¥ Files in the queue (unprocessed)

ğŸ”„ Files currently being processed

âœ… Files successfully processed

ğŸ“ Name of the last processed file

ğŸ³ Docker Setup
ğŸ”¹ Build Docker Image
bash
Copy code
docker build -t file-processor .
ğŸ”¹ Run in Watch Mode with Dashboard
bash
Copy code
docker run -p 5000:5000 file-processor --watch
ğŸ”¹ Run for Single File (example)
bash
Copy code
docker run -v "$(pwd)/watch_dir:/app/watch_dir" file-processor --input watch_dir/unprocessed/test.txt
ğŸ“ Ensure the watch_dir folder is mounted as a Docker volume for file accessibility.

ğŸ“¤ Uploading Files
To process files:

Drop them in the watch_dir/unprocessed/ folder (locally or inside Docker volume).

Optional enhancements:

Add a FastAPI upload route

Use tools like rsync or scp for automated upload from remote sources

ğŸ“¡ Monitoring Uptime
Use services like:

Better Uptime

UptimeRobot

to monitor availability of the dashboard at http://localhost:5000.

ğŸ§¼ Makefile Commands
Command	Description
make run	Default run with no arguments
make input	Process a single file
make watch	Watch mode for real-time folder monitoring
make clean	Clean the processed directories
make docker	Build Docker image for deployment

âœ… Project Achievements
Youâ€™ve implemented a functional file-processing system that includes:

ğŸ”§ Modular architecture

ğŸ”„ Real-time folder watcher

ğŸŒ Live dashboard (Flask)

ğŸ–¥ï¸ CLI control via arguments or Makefile

ğŸ³ Docker-compatible deployment

ğŸ“ˆ Scalable and extensible design


ğŸ“¸ Dashboard Output
ğŸ§©Output -[ output_page.png]

ğŸ§© Design Overview
Processing Logic: file_processor.py handles core operations.

CLI Interface: main.py controls single vs watch mode.

Watcher: watcher.py monitors file arrival.

Dashboard: dashboard.py shows live status on the web.

These components are decoupled to support modular upgrades and independent testing.

âš–ï¸ Known Tradeoffs & Limitations
âŒ No concurrent processing (one file at a time for simplicity)

âŒ No database (in-memory state tracking only)

âŒ Minimal error handling (logging/retries needed for production)

âŒ No user authentication for dashboard

ğŸ“ˆ Future Improvements
To scale this system or move to production:

ğŸ§µ Add multithreading/multiprocessing for concurrency

ğŸ“¦ Integrate Celery or Kafka for high-throughput tasks

ğŸ” Add authentication & file-type validation

ğŸ“Š Connect Prometheus + Grafana for observability

ğŸ—ƒï¸ Use persistent database (e.g., PostgreSQL, Redis)

This architecture reflects the foundations of production frameworks like Apache Beam, Airflow, and Kafka Streams â€” but simplified for clarity and learning.

